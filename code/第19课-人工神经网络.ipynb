{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本课提纲\n",
    "- 人工神经网络\n",
    "- 基于pytorch的神经网络\n",
    "- 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 人工神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络这个概念来源于人体自身的神经系统，人体有各种感知器官来收集外界的信息，然后通过神经系统传送信息，汇总到大脑处进行计算，由大脑进行汇总信息后进行决策，返回决策动作。这种汇总信息进行计算处理的思路，如果用计算机来模拟的话，就称之为人工神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在前面的感知机和逻辑回归的课程已经学习到，可以通过一个加权求和将外界信息进行汇总，然后经过一个激活函数来输出的判断。而那些权重就是感知机的参数，也就是要学习训练的参数，它是通过真实的标签结果和感知机的判断结果进行比对，通过梯度下降逐步修正学习到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络和感知机类似，只不过在信息汇总处理上稍微复杂一些。可以认为有多个感知机都在同时汇总外界信息，在汇总之后，再由另一个感知机来汇总前面感知机的输出。所以可以认为神经网络只不过是感知机的组合。这次课我们来学习如何训练一个常规的全连接的神经网络，从结构上，它就是中间多了一个或多个隐层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 基于pytorch的神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来看一下，如何基于pytorch来构建一个计算机世界的神经网络，首先加载一些必要的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还是以最为熟悉的Iris数据为例子，读入数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前课程一样，取出前100个样本，只包括了两种花，做一个简化的二分类建模任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:100,:4].values\n",
    "y = df.iloc[:100,4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们会使用所有的四个特征，所以将四个特征进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = np.copy(X)\n",
    "X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()\n",
    "X_std[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()\n",
    "X_std[:,2] = (X[:,2] - X[:,2].mean()) / X[:,2].std()\n",
    "X_std[:,3] = (X[:,3] - X[:,3].mean()) / X[:,3].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后设置一个dict，将y转换为0-1的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'Setosa':0,'Versicolor':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([label_dict[i] for i in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置几个超参数，这里设置了4个输入特征，隐层特征为5个，1个最终输出，100次迭代，以及学习率0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 4\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "num_epochs = 300\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后再设置对应的神经网络的权重参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn([input_size,hidden_size],requires_grad=True)\n",
    "b1 = torch.randn([hidden_size,1],requires_grad=True)\n",
    "w2 = torch.randn([hidden_size,output_size],requires_grad=True)\n",
    "b2 = torch.randn([output_size,1],requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立一个Model函数，以汇总计算输入特征，可以看到，首先将4个特征和W1进行矩阵相乘，得到了隐层特征，此时隐层特征有5个，然后通过relu激活函数，得到中间的输出结果保存为active，随后再将这个中间结果再和w2进行矩阵相乘，得到输出后再通过sigmoid转换为概率值，得到最终输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    hidden_layer =  torch.matmul(x,w1)\n",
    "    active = torch.relu(hidden_layer)\n",
    "    output_layer = torch.matmul(active,w2)\n",
    "    output = torch.sigmoid(output_layer)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用nn.BCELoss定义损失函数，然后再定义一个优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  \n",
    "optimizer = torch.optim.SGD([w1,b1,w2,b2], lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后我们用一个循环来训练，每次循环中将数据转换为torch的tensor格式，用定义好的model将输入数据进行汇总，再将预测值outputs和真实的标签targets计算损失函数，后面类似的是计算以loss为目标的各个参数的梯度，同时进行梯度修正。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.0356\n",
      "Epoch [100/300], Loss: 0.0158\n",
      "Epoch [150/300], Loss: 0.0101\n",
      "Epoch [200/300], Loss: 0.0073\n",
      "Epoch [250/300], Loss: 0.0057\n",
      "Epoch [300/300], Loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.tensor(X_std,dtype=torch.float)\n",
    "    targets = torch.tensor(y.reshape(-1,1),dtype=torch.float)\n",
    "    outputs = model(inputs)\n",
    "    # Forward pass\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss_list.append(loss.tolist())\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面可以画出loss的曲线图，可以观察到损失函数确实是随着每次迭代是越来越小的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucXHV9//HXe2bvl2RDdhNCEhIgEYnKNaJStV5QQS1oRYFKRauitpTa1gvUliq1rWLr7SetRaX1jhRvUVDwAlpbbotCJCAYQjBLQrIJ5L7Zze5+fn+cs8lkmd1skp09Z3fez8djHjPne75z5vOdszuf+X7Pd85RRGBmZpY3hawDMDMzK8cJyszMcskJyszMcskJyszMcskJyszMcskJyszMcskJyvaQ9EZJNx/kc1dIetE4h5R7kn4g6cKs48iKpBdIejDrOGxqcoKapCStlnT6eG4zIr4aES8fw2v/l6QPD3vuMyLi1gN5PUkLJYWk7elttaRLDzDsTEXEmRHxxYl+XUlvlvSLiX7d4SLifyLi2KzjAJD0Ikldh7iNl0r6jaSdkm6RtGCUugvTOjvT55xesu6Zkm6StFGSf2x6kJygLA/aIqIFOAf4O0kvG+8XkFQz3tuc6vL0nilR0c8rSe3At4C/Aw4DOoFvjPKUrwO/AmYCHwCul9SRrtsNXAe8tWIBV4OI8G0S3oDVwOkjrHs7sBJ4AlgGHFGy7uXAg8AW4N+AnwFvS9e9GfhF+ljAJ4ANad3lwDOBi0j++fqA7cD3hscDFIG/AR4GtgF3A/PLxLkQCKCmpOxO4L0ly0cA3wS6gUeAS0rWNQJfBJ4EHgDeB3QNe4/en8beC9TsZ3unknwobQXWAx9PyxuArwCbgM3AXcDsdN2tJe9fAfhb4NH0ffsSMH1YWy8EfgdsBD5wCPt/z74qs2468AVgHfAY8GGgmK47Bvhp2paNwFdJviCM9p6tBt6Tlm0h+dBuSOu/qMx7XrZuuv59aVxrgbel78miEdpxK/CPwP8CPcAi4C3pvt4GrALekdZtTusMkvxdbk/3dQG4lORvcRNJ0jhshNe7CPi/kuWhbT69TN2npe9Pa0nZ/wDvHFZvERBZf15M1pt7UFOMpJcA/wy8AZhD8mF5bbquHbgeuIzkW9+DwGkjbOrlwAtJ/hHbgHOBTRFxNcmH2pUR0RIRf1DmuX8FnA+8EpgG/AmwcwyxP5ckCa5MlwvA94B7gbnAS4F3S3pF+pS/J/ngPxp4GXBBmc2eD7wqbcPgfrb3KeBTETGN5IP8urT8QpIP/fkk79s7ST64hntzentxGlML8JlhdZ4PHJu+9uWSjhvtPTlIXwT6ST4cTyLZl29L14nk7+MI4DiSNn1w2PP3vGcR0Z+WvQE4AzgKOJ6knSMpW1fSGSR/G6ensf3+GNryxySJo5W9if/VJH9XbwE+IenkiNgBnAmsTf8uWyJiLXAJ8Jr0tY4g+TJz1Qiv9QySvw0A0m0+nJaXq7sqIraVlN07Ql07SE5QU88bgWsi4pcR0UuSjJ4naSFJwlgREd9KP3g+DTw+wnZ2k3woPB1QRDwQEevGGMPbgL+NiAcjcW9EbBql/kZJPcBtJL2676TlzwY6IuKKiOiLiFXA54Dz0vVvAP4pIp6MiK60PcN9OiLWRETPGLa3G1gkqT0itkfE7SXlM0m+6Q9ExN0RsbXMa72RpNe1KiK2k7z35w0bKvtQRPRExL0kH2gnjPK+HDBJs0k+qN8dETsiYgNJT/g8gIhYGRE/iojeiOgGPs5TE0Xpe1ZatjYiniBJ8ieOEsZIdd8A/GdErIiIncCHxtCk/0rr90fE7oi4ISIeTv+ufgbcDLxglOe/g6Sn2pX+P3wQOGeE4csWkl5fqS0k/weHUtcOkhPU1HMEyTdNANIPyk0kPYYjgDUl6wIoe1A5In5K8u3/KmC9pKslTRtjDPNJvnmOVTvJP/x7SIaMatPyBcARkjYP3UiGDmen6/dpz7DH5cr2t723kvQYfyPpLkmvTsu/DNwEXCtpraQrJdXyVPu89+njmpLtw75fCHam7d6HpCNLJo5sL/M6o1lA8v6tK2njfwCz0m3PknStpMckbSUZumwfto1y7+N+4x5D3bHsr+H2qSPpTEm3S3oibdsreWr8pRYA3y55Lx4ABth3nwzZTtIzKzWNZDjxUOraQXKCmnrWkvxTAiCpmeTb/2MkY//zStapdHm4iPh0RJxCMmzxNOC9Q6v2E8MakiGyMUt7Jv8K7AL+tGQ7j0REW8mtNSJema7fpz0kifEpmx4W14jbi4jfRsT5JB/mHyU56N2cfnP/UEQsIRkSfTXwpjKvtc97DxxJMtS2/gDeCiLidyXDVKMlgnLWkBwbaS9p47SIGBp6+meS9+T4dCjzApJhv31COMDXHKux7K/h9sQiqZ7k+OG/kBwDbANuZG/85eJeA5w5bJ83RMRjZequoKRHm/7vHJOWl6t7tKTSHtMJI9S1g+QENbnVSmooudUAXwPeIunE9B/6n4A7ImI1cAPwLEmvSev+GXB4uQ1Lerak56Q9hR0kiWMgXb2e5BjLSD4P/IOkxensq+MlzRxjmz4CvE9SA8mEia2S3i+pUVIxnb777LTudcBlkmZImgtcvJ9tj7o9SRdI6oiIQZLJEAADkl4s6VmSiiQTKHaXvBelvg78paSjJLWQvPffKDmOM940bP83pMOwNwP/KmmapIKkYyQNDeO1knz735y+Z+8daeMVcB3J3+ZxkpqAyw/w+XVAPckEl35JZ5IcXxuyHpgpaXpJ2WeBfxyaLi6pQ9LZI2z/28AzJb0u/fu7HFgeEb8ZXjEiHgLuAf4+fe9fS3K87Zvp6yjdRl263JD+P9oBcIKa3G4kOVg/dPtgRPyEZJrsN0m+sR7D3uMPG4HXA1eSDPstIZm11ltm29NIjs88STJUtYnkmyskM8SWpMMm3ynz3I+TfBjdTPKB/gWSGXdjcUP6mm+PiAHgD0iOYTxCMuvs8yQTFgCuIBmifAT4MckEkHJtAZJe2n62dwawIh1W+xRwXkTsIkni16dteYBk5uNXyrzENSTDgT9Pt78L+PMxtvtgnMa++78n/eLxJpIPxvtJ3svrSSbMQHLc52SS4yU3kEyrnhAR8QOS44S3kEyEuS1dNeI+G/b8bSSTHq4jadcfkcxSHVr/G5IvCavSv80jSPbjMuBmSduA24HnjLD9buB1JDMHn0zrDR2fRNJnJX225CnnAUvTuh8Bzkm3AUlPuoe9PaoekklJdgCUHIawapTOkusC3hgRt2Qdz6GS9C6SpDKW2WGWsXQG431AfQV7mTaJuQdVZSS9QlJbOtzwNyTj97fv52m5JGmOpN9Lh7GOBf6aZJjGckrSayXVSZpBcpzve05ONhInqOrzPJIZdhtJhrteM2w68WRSRzJDbRvJj0+/SzJN3fLrHSTHkB4mOY73rmzDsTzzEJ+ZmeWSe1BmZpZLuTkZ5Fi1t7fHwoULsw7DzMwO0t13370xIjr2V2/SJaiFCxfS2dmZdRhmZnaQJD26/1oe4jMzs5xygjIzs1xygjIzs1xygjIzs1xygjIzs1xygjIzs1xygjIzs1yqugT1g1+v4/ZVo1193MzM8qDqEtRHf/gbvnbH77IOw8zM9qPqElRTXQ07+3x2fzOzvKvCBFVkZ1+5q3WbmVmeVF+Cqq9hhxOUmVnuVTRBSTpD0oOSVkq6tMz6N0vqlnRPentbJeMBaKotsrPXQ3xmZnlXsbOZSyoCVwEvA7qAuyQti4j7h1X9RkRcXKk4hmuq9xCfmdlkUMke1KnAyohYFRF9wLXA2RV8vTFJjkG5B2VmlneVTFBzgTUly11p2XCvk7Rc0vWS5pfbkKSLJHVK6uzu7j6koJrratyDMjObBCqZoFSmLIYtfw9YGBHHAz8GvlhuQxFxdUQsjYilHR37vQjjqJrqaujtH2RgcHgoZmaWJ5VMUF1AaY9oHrC2tEJEbIqI3nTxc8ApFYwHSIb4AA/zmZnlXCUT1F3AYklHSaoDzgOWlVaQNKdk8SzggQrGAySTJAAP85mZ5VzFZvFFRL+ki4GbgCJwTUSskHQF0BkRy4BLJJ0F9ANPAG+uVDxDhnpQOzzV3Mws1yqWoAAi4kbgxmFll5c8vgy4rJIxDNdUlzTZPSgzs3yrvjNJ1HmIz8xsMqjCBDXUg/IQn5lZnlVdgmr2JAkzs0mh6hJUU62PQZmZTQbVl6Dq/TsoM7PJoPoS1J5p5u5BmZnlWdUlqIaaIhL0uAdlZpZrVZegCgXRWFv0RQvNzHKu6hIUJFPNPUnCzCzfqjJBNdf7mlBmZnlXlQmqsdZX1TUzy7uqTFDN9TXuQZmZ5VxVJqimuiLbPc3czCzXqjJBtTbUsH3X7qzDMDOzUVRngqqvZbuvB2VmlmtVmaBaGmrYtssJyswsz6oyQbU2JL+DGhiMrEMxM7MRVGWCaqlPzmi+3b0oM7PcqsoENa2hFoBtvZ4oYWaWV1WZoFoakh6Uj0OZmeVXdSaooSE+z+QzM8utqkxQrXt6UB7iMzPLqypPUO5BmZnlVZUmqHSShBOUmVluVWWC8jEoM7P8q8oE1VRXpCAfgzIzy7OqTFCSaKmv8Q91zcxyrCoTFCTHoXwMyswsv6o4QdWwzcegzMxyq7oTlI9BmZnlVkUTlKQzJD0oaaWkS0epd46kkLS0kvGUaqmv8Sw+M7Mcq1iCklQErgLOBJYA50taUqZeK3AJcEelYinHx6DMzPKtkj2oU4GVEbEqIvqAa4Gzy9T7B+BKYFcFY3mK1oYatvZ4iM/MLK8qmaDmAmtKlrvSsj0knQTMj4jvj7YhSRdJ6pTU2d3dPS7BtTXVsnVXPxG+aKGZWR5VMkGpTNmebCCpAHwC+Ov9bSgiro6IpRGxtKOjY1yCm95Yy8Bg+DiUmVlOVTJBdQHzS5bnAWtLlluBZwK3SloNPBdYNlETJdoa6wDYvNPDfGZmeVTJBHUXsFjSUZLqgPOAZUMrI2JLRLRHxMKIWAjcDpwVEZ0VjGmP6U3JCWO3+DiUmVkuVSxBRUQ/cDFwE/AAcF1ErJB0haSzKvW6Y9XW6ARlZpZnNZXceETcCNw4rOzyEeq+qJKxDDfUg/IQn5lZPlXtmSSGjkG5B2Vmlk/Vm6CGelA9fRlHYmZm5VRtgmqoLVJfU2CLh/jMzHKpahMUJL+F8hCfmVk+VXWCamuq9SQJM7Ocqu4E1VjnHpSZWU5VdYKa1ljLZicoM7NcquoE1dZUy5adnsVnZpZH1Z2gPEnCzCy3qjtBNdWyo2+Avv7BrEMxM7NhqjpBzWhOzibxpIf5zMxyp6oT1Mw0QW3a7gRlZpY3VZ2gDmuuB+CJHU5QZmZ5U+UJKu1B7ejNOBIzMxvOCQr3oMzM8qiqE1RbYy0FOUGZmeVRVSeoQkHMaKpzgjIzy6GqTlCQDPM5QZmZ5Y8TVHMdm5ygzMxyp+oT1MwW96DMzPKo6hOUj0GZmeVT1Seomc11PLmzj4HByDoUMzMrUfUJ6rDmOiJgs8/HZ2aWK1WfoGa2JKc78kQJM7N8qfoE1dGaJKiN23y6IzOzPHGCShNU93YnKDOzPHGCShPUhq1OUGZmeVL1Caq1vob6moJ7UGZmOVP1CUoSHa31dPsYlJlZrlR9ggKY5QRlZpY7FU1Qks6Q9KCklZIuLbP+nZJ+LekeSb+QtKSS8YzEPSgzs/ypWIKSVASuAs4ElgDnl0lAX4uIZ0XEicCVwMcrFc9oOlrrfQzKzCxnKtmDOhVYGRGrIqIPuBY4u7RCRGwtWWwGMjnfUEdLA0/s6KOvfzCLlzczszIqmaDmAmtKlrvSsn1I+jNJD5P0oC4ptyFJF0nqlNTZ3d097oEOTTXftMO9KDOzvKhkglKZsqf0kCLiqog4Bng/8LflNhQRV0fE0ohY2tHRMc5hlvxY18ehzMxyo5IJqguYX7I8D1g7Sv1rgddUMJ4RzUoT1Hr/WNfMLDcqmaDuAhZLOkpSHXAesKy0gqTFJYuvAn5bwXhGNGd6AwCPb92VxcubmVkZNZXacET0S7oYuAkoAtdExApJVwCdEbEMuFjS6cBu4EngwkrFM5qZLfXUFMTjW3qyeHkzMyujYgkKICJuBG4cVnZ5yeO/qOTrj1WxIGZPa2DdFvegzMzywmeSSM2eVs/jTlBmZrkxpgQl6ctjKZvM5kxvdIIyM8uRsfagnlG6kJ4l4pTxDyc7h09PhvgiMvmtsJmZDTNqgpJ0maRtwPGStqa3bcAG4LsTEuEEmTO9gZ7dA2zt6c86FDMzYz8JKiL+OSJagY9FxLT01hoRMyPisgmKcUIcnk41X7fVM/nMzPJgrEN835fUDCDpAkkfl7SggnFNuKHfQnkmn5lZPow1Qf07sFPSCcD7gEeBL1UsqgwcPr0RgHWbnaDMzPJgrAmqP5LZA2cDn4qITwGtlQtr4s1uradYEI9t3pl1KGZmxth/qLtN0mXAHwMvSGfx1VYurIlXUywwZ3oDjz3pY1BmZnkw1h7UuUAv8CcR8TjJZTM+VrGoMjJvRiNdTlBmZrkwpgSVJqWvAtMlvRrYFRFT6hgUwLwZTU5QZmY5MdYzSbwBuBN4PfAG4A5J51QysCzMm9HI+m276O0fyDoUM7OqN9ZjUB8Anh0RGwAkdQA/Bq6vVGBZmDejiYhkJt/C9uaswzEzq2pjPQZVGEpOqU0H8NxJY96MZKr5Y5s9zGdmlrWx9qB+KOkm4Ovp8rkMu4zGVDCUoLqe9FRzM7OsjZqgJC0CZkfEeyX9IfB8QMBtJJMmppTDpzVQLIg1T7gHZWaWtf0N030S2AYQEd+KiL+KiL8k6T19stLBTbSaYoF5Mxp59An3oMzMsra/BLUwIpYPL4yITmBhRSLK2IKZzazeuCPrMMzMqt7+ElTDKOsaxzOQvFg4s4nVm3b4ulBmZhnbX4K6S9LbhxdKeitwd2VCytbCmc1s29XPEzv6sg7FzKyq7W8W37uBb0t6I3sT0lKgDnhtJQPLysL2JgBWb9rJzJb6jKMxM6teoyaoiFgPnCbpxcAz0+IbIuKnFY8sIwtmJj/QXb1xB6csmJFxNGZm1WtMv4OKiFuAWyocSy7Mn9FEQfDoJk+UMDPL0pQ7G8ShqqspMHdGI6s8k8/MLFNOUGUs6mhh5YbtWYdhZlbVnKDKWDy7lVUbdzAw6KnmZmZZcYIqY1FHC339g6zxGSXMzDLjBFXGotktAB7mMzPLkBNUGYtmJQnqt05QZmaZcYIqY1pDLbOn1bsHZWaWoYomKElnSHpQ0kpJl5ZZ/1eS7pe0XNJPJC2oZDwHYvGsVh5avy3rMMzMqlbFEpSkInAVcCawBDhf0pJh1X4FLI2I40kuH39lpeI5UE8/PElQ/QODWYdiZlaVKtmDOhVYGRGrIqIPuBY4u7RCRNwSEUNT5W4H5lUwngNy3Jxp9PYPstpnlDAzy0QlE9RcYE3JcldaNpK3Aj8ot0LSRZI6JXV2d3ePY4gjO27ONADuX+dhPjOzLFQyQalMWdlfvkq6gOQs6R8rtz4iro6IpRGxtKOjYxxDHNmiWS3UFsX9a7dOyOuZmdm+xnSy2IPUBcwvWZ4HrB1eSdLpwAeA34+I3grGc0Dqagoc09HCA+ucoMzMslDJHtRdwGJJR0mqA84DlpVWkHQS8B/AWRGxoYKxHJQlR0zjficoM7NMVCxBRUQ/cDFwE/AAcF1ErJB0haSz0mofA1qA/5Z0j6RlI2wuE8+aO53ubb08vmVX1qGYmVWdSg7xERE3AjcOK7u85PHplXz9Q3X8vDYA7u3azOHTD884GjOz6uIzSYxiyZxpFAtiedfmrEMxM6s6TlCjaKwr8rTZrSzv2pJ1KGZmVccJaj9OmDed5V1biPC1oczMJpIT1H6cML+NLT27fQl4M7MJ5gS1H89eOAOAu1c/mXEkZmbVxQlqP45ub6GtqZbOR5/IOhQzs6riBLUfhYI45cgZdD7qHpSZ2URyghqDpQsPY1X3DjZtz82ZmMzMpjwnqDE49ajDALjjEQ/zmZlNFCeoMTh+3nSa64rc9vCmrEMxM6saTlBjUFsscOpRh/F/D2/MOhQzs6rhBDVGpx3TzsPdO1i/1SeONTObCE5QY3TaopkA/M9v3YsyM5sITlBjtGTONGa11nPrg7m7bJWZ2ZTkBDVGknjRsR38/KFu+gcGsw7HzGzKc4I6AC8+dhZbd/Xzy9/58htmZpXmBHUAfm9xO3XFAjeveDzrUMzMpjwnqAMwraGWFz6tnRt+vY7BQV9+w8yskpygDtCrjz+CdVt28cvf+dx8ZmaV5AR1gF563Czqagp8f/m6rEMxM5vSnKAOUGtDLS8+toMbf72OAQ/zmZlVjBPUQXjV8UewYVsvnat98lgzs0pxgjoIL336LBpqCyy7d23WoZiZTVlOUAehub6GM585h+/es5Ydvf1Zh2NmNiU5QR2kC567gO29/XznnseyDsXMbEpygjpIJx/ZxnFzpvGV239HhCdLmJmNNyeogySJC557JA+s2+pTH5mZVYAT1CF4zYlzaamv4Su3P5p1KGZmU44T1CForq/hnFPm8f3la3lsc0/W4ZiZTSlOUIfo7S88GoB/u2VlxpGYmU0tFU1Qks6Q9KCklZIuLbP+hZJ+Kalf0jmVjKVS5rY18vql87mucw1r3YsyMxs3FUtQkorAVcCZwBLgfElLhlX7HfBm4GuVimMi/OmLjgHg3299OONIzMymjkr2oE4FVkbEqojoA64Fzi6tEBGrI2I5MKkvUTtvRhPnnDKfb9y1hjVP7Mw6HDOzKaGSCWousKZkuSstO2CSLpLUKamzu7t7XIIbb3/+kkUUC+LDN9yfdShmZlNCJROUypQd1C9aI+LqiFgaEUs7OjoOMazKOKKtkYtfsoibVqznZw/lM4mamU0mlUxQXcD8kuV5wJQ+u+rbXnAUC2c28aFlK+jrn9SjlmZmmatkgroLWCzpKEl1wHnAsgq+Xubqa4r8/R88g1Ubd/Bvt3rauZnZoahYgoqIfuBi4CbgAeC6iFgh6QpJZwFIerakLuD1wH9IWlGpeCbKi58+i7NPPIL/99OV3LPGp0AyMztYmmwnOl26dGl0dnZmHcaotvTs5sxP/pz62iI3XPJ8mupqsg7JzCw3JN0dEUv3V89nkqiA6Y21/MsbTmD1ph18cNkKn+3czOwgOEFVyGnHtHPxixdxXWcXX7rNJ5M1MztQTlAV9JenP43Tj5vNFd+/n/9duTHrcMzMJhUnqAoqFMQnzj2BYzqaeedX7mbF2i1Zh2RmNmk4QVVYa0Mt17z52bTW1/CmL9zJyg3bsg7JzGxScIKaAPNmNPHVtz8XSbzx83c4SZmZjYET1AQ5qr2Zr77tOQwMwjmfvY1f/e7JrEMyM8s1J6gJdOzhrXzzXc9jemMtf/S5O7h5xeNZh2RmlltOUBNswcxmrn/naSye3cJFX76bj9/8IIOD/p2UmdlwTlAZ6Git57p3PI/XnzKPT/90JRf+5508vmVX1mGZmeWKE1RGGmqLXHnO8fzTa59F5+onecUnf86ye9f6rBNmZiknqAxJ4o+ecyQ3XPJ8FrY3c8nXf8Uff+FOVm7YnnVoZmaZc4LKgaM7WvjmO5/Hh856Bvd2bebMT/2cj/zgN2zdtTvr0MzMMuMElRM1xQIXnraQW97zIs4+cS6f/dnDPP8jP+XTP/kt25yozKwK+XIbOXXfY1v45I9/y48fWM/0xloufN4CLnjuAmZNa8g6NDOzQzLWy204QeXcr7u28KmfPMSPH9hATUG86vg5vOl5Czn5yDYkZR2emdkBc4KaYh7ZuIMv3baa6zu72Nbbz9HtzfzhyXN5zUlzmTejKevwzMzGzAlqitre28+Ny9fxzV92cccjTwBw4vw2Xv6M2bx8yeEsmtWScYRmZqNzgqoCa57YybJ713Lzise5tyu5lMfR7c289LhZ/N6idp698DCa6325eTPLFyeoKrNuSw8/vn89N9+/njtWPUHfwCA1BXHSkW0875h2li6YwQnz25jeWJt1qGZW5ZygqlhP3wCdjz7B/67cxG0Pb+TXj21h6HR/x3Q0c9KRMzhxfhsnzm9j0awWGmqL2QZsZlVlrAnK4z9TUGNdkRcs7uAFizsA2LprN8vXbOGeNU9yz5rN3PKbDVx/dxcAxYJYOLOJpx8+jWMPb+XYw1t5+uGtzJ/RRKHgWYJmlh0nqCowraGW5y9u5/mL2wGICLqe7GF51xYefHwrv3l8G/et3cKN961jqENdX1NgwcwmFsxs5qj2ZhbMbGLhzGYWtjdz+LQGik5eZlZhTlBVSBLzD2ti/mFNvOr4OXvKd/T289D6bTz4+DYe7t7O6k07Wb1xBz97qJu+/sE99WoKYva0BuZMb+CItkbmtDVwxPTGPctHtDUyo6nWv9Mys0PiBGV7NNfXcNKRMzjpyBn7lA8OBo9v3cXqjTt4ZNMO1m7uYd3mXTy2uYd71mzmh/ftom9gcJ/n1BbFzOZ6OlrraW+po72lnvbW+uS+pY6OdPmw5jqmN9ZSW/RZt8xsX05Qtl+Fgvb0jE5b1P6U9YODwaYdfUni2tLD2s272LCtl43bk1v39l4eWLeNjdt76R/h4owt9TVMb6ylramWGU11TG+qpS1dbmvcuzy9sZaWhhpa65P75voi9TWe5GE2FTlB2SErFERHa9JbOmF+24j1BgeDLT279yStjdv7eHJHH5t37mZzTx9bdu5mc89uNu/sY+2Wnj3LA/u54nBdsUBLQw0t9emtoYbW9H5ouaWuhqb6GprqijTWFmlM75vqijSk9411RZpqa2ioK1BXLHiI0ixjTlA2YQoFMaO5jhnNdSye3Tqm50QE23v72bxzN1t6drN552629/Ynt13J4229/Wzf1c+OtHzbrn4e37qL7d1J+bbe/n2OoY1FsaARE1lDbZH6mgJ1NQXqawrU1yTL9bUF6opF6mv3lu+tU6B+pOcNPa4tUFMQxYKcHM1wgrKck0RrQy2tDbXMP4Tt9PUP0tM3wM7d/cl93wC7dif3PbsH6Env95b309M3SE9J/aF6W3ftpq9/kN7+QXp3D9JsH8cxAAAJO0lEQVTbP7BneaQhzANrM9QWC9QWRG1N4SmPawqiboTHtTVJ76/c49qCkm3V7H1esaA0Ke5NjnvuiyOUFwol68uUF0SxuG95QTjp2gGraIKSdAbwKaAIfD4iPjJsfT3wJeAUYBNwbkSsrmRMVp3q0p7LdCp7Jo3+gUH6BpLENXTf2z+QJLP+ksd71u+7rn8g2D0wyO499/s+7h8I+oY93tHbP0L9pz4vS09NgIVhCU4UCqIgUVTyuFiAgtKyQlIuJT3cYlq3kC6X1isURFHpcwt7t/fUuuxdX1K3WEgS6sivuTe2PWUldYcS8lB8BQmG4knvNXQPe2IrfY7YW6dQ2PtcDT0nrSuVPJ/S7eytQxrTPs/RvnXz+AWiYglKUhG4CngZ0AXcJWlZRNxfUu2twJMRsUjSecBHgXMrFZNZpdUUC9QUCzTVZR3JU0UE/YOxT5IbHEzKBvbcD+6pM7DPusG9ywMjlO9ZPzhsm/tue9/nD3vNCCKSdQODScwD6fJgBIODMBBBX/8gAxEMRnJsc8/6PXXZ+3gw9q0bSdlgkLxOyWuOQwd4UhtLUpPg9steOiFnoKlkD+pUYGVErAKQdC1wNlCaoM4GPpg+vh74jCTFZDv/ktkkIInaoqgtQiOe+VhOxLDkFnsT2d5EtzdRDg7GU+oORhDD7kvLS19jb9m+y2N6Dkkcw58TpPcliXgw/Uh9SoyDZZ5TUocysQxGUDNBP9SvZIKaC6wpWe4CnjNSnYjol7QFmAlsrGBcZmZlScnQYJEkkVu2KvnryHIpdnjPaCx1kHSRpE5Jnd3d3eMSnJmZ5VslE1QX7DPxah6wdqQ6kmqA6cATwzcUEVdHxNKIWNrR0VGhcM3MLE8qmaDuAhZLOkpSHXAesGxYnWXAhenjc4Cf+viTmZlBBY9BpceULgZuIplmfk1ErJB0BdAZEcuALwBflrSSpOd0XqXiMTOzyaWiv4OKiBuBG4eVXV7yeBfw+krGYGZmk5NPIW1mZrnkBGVmZrnkBGVmZrmkyTZpTlI38OghbKKdqf1DYLdv8pvqbXT7JrfxaN+CiNjvb4YmXYI6VJI6I2Jp1nFUits3+U31Nrp9k9tEts9DfGZmlktOUGZmlkvVmKCuzjqACnP7Jr+p3ka3b3KbsPZV3TEoMzObHKqxB2VmZpOAE5SZmeVS1SQoSWdIelDSSkmXZh3PeJG0WtKvJd0jqTMtO0zSjyT9Nr2fkXWcYyXpGkkbJN1XUla2PUp8Ot2nyyWdnF3kYzNC+z4o6bF0H94j6ZUl6y5L2/egpFdkE/XYSZov6RZJD0haIekv0vIpsQ9Had9U2ocNku6UdG/axg+l5UdJuiPdh99Ir1KBpPp0eWW6fuG4BRMRU/5Gcjb1h4GjgTrgXmBJ1nGNU9tWA+3Dyq4ELk0fXwp8NOs4D6A9LwROBu7bX3uAVwI/ILnw5XOBO7KO/yDb90HgPWXqLkn/VuuBo9K/4WLWbdhP++YAJ6ePW4GH0nZMiX04Svum0j4U0JI+rgXuSPfNdcB5aflngXelj/8U+Gz6+DzgG+MVS7X0oE4FVkbEqojoA64Fzs44pko6G/hi+viLwGsyjOWARMTPeepFK0dqz9nAlyJxO9Amac7ERHpwRmjfSM4Gro2I3oh4BFhJ8recWxGxLiJ+mT7eBjwAzGWK7MNR2jeSybgPIyK2p4u16S2AlwDXp+XD9+HQvr0eeKmkcldLP2DVkqDmAmtKlrsY/Y9qMgngZkl3S7ooLZsdEesg+YcCZmUW3fgYqT1Tab9enA5xXVMyJDup25cO9ZxE8g18yu3DYe2DKbQPJRUl3QNsAH5E0vPbHBH9aZXSduxpY7p+CzBzPOKolgRVLptPlfn1vxcRJwNnAn8m6YVZBzSBpsp+/XfgGOBEYB3wr2n5pG2fpBbgm8C7I2LraFXLlOW+jWXaN6X2YUQMRMSJwDySHt9x5aql9xVrY7UkqC5gfsnyPGBtRrGMq4hYm95vAL5N8se0fmiYJL3fkF2E42Kk9kyJ/RoR69MPhEHgc+wdApqU7ZNUS/Lh/dWI+FZaPGX2Ybn2TbV9OCQiNgO3khyDapM0dJHb0nbsaWO6fjpjH8YeVbUkqLuAxekslDqSA3nLMo7pkElqltQ69Bh4OXAfSdsuTKtdCHw3mwjHzUjtWQa8KZ0J9lxgy9Aw0mQy7JjLa0n2ISTtOy+dJXUUsBi4c6LjOxDpsYcvAA9ExMdLVk2JfThS+6bYPuyQ1JY+bgROJznWdgtwTlpt+D4c2rfnAD+NdMbEIct6xshE3UhmCz1EMpb6gazjGac2HU0yQ+heYMVQu0jGf38C/Da9PyzrWA+gTV8nGSLZTfLN7K0jtYdkaOGqdJ/+GliadfwH2b4vp/EvT//Z55TU/0DavgeBM7OOfwztez7J8M5y4J709sqpsg9Had9U2ofHA79K23IfcHlafjRJcl0J/DdQn5Y3pMsr0/VHj1csPtWRmZnlUrUM8ZmZ2STjBGVmZrnkBGVmZrnkBGVmZrnkBGVmZrnkBGU2jiQNlJzR+h6N45nzJS0sPQu62VRXs/8qZnYAeiI5RYyZHSL3oMwmgJLrdn00vc7OnZIWpeULJP0kPcnoTyQdmZbPlvTt9Jo890o6Ld1UUdLn0uv03Jz+0h9Jl0i6P93OtRk102xcOUGZja/GYUN855as2xoRpwKfAT6Zln2G5HITxwNfBT6dln8a+FlEnEBy/agVafli4KqIeAawGXhdWn4pcFK6nXdWqnFmE8lnkjAbR5K2R0RLmfLVwEsiYlV6stHHI2KmpI0kp8XZnZavi4h2Sd3AvIjoLdnGQuBHEbE4XX4/UBsRH5b0Q2A78B3gO7H3ej5mk5Z7UGYTJ0Z4PFKdcnpLHg+w9zjyq0jOaXcKcHfJWafNJi0nKLOJc27J/W3p4/8jObs+wBuBX6SPfwK8C/ZcPG7aSBuVVADmR8QtwPuANuApvTizycbfsszGV2N6JdIhP4yIoanm9ZLuIPlieH5adglwjaT3At3AW9LyvwCulvRWkp7Su0jOgl5OEfiKpOkkZwf/RCTX8TGb1HwMymwCpMeglkbExqxjMZssPMRnZma55B6UmZnlkntQZmaWS05QZmaWS05QZmaWS05QZmaWS05QZmaWS/8fCiW1ZpYIcPMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(range(1, len(loss_list) + 1), loss_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Logistic Regression - Learning rate 0.01')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实pytorch中提供了很多现成的函数和模块，我们可以学着直接使用它们，这样可以少写点自定义的代码，编码更快速而统一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仍是定义一些超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 4\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "num_epochs = 300\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来构造一个类名字叫作NeuralNet，类的逻辑就定义了一个模型是如何汇总计算的，这个类的角色就和我们前面定义的model函数是一样的。然后使用这个类构造了一个model实例。所以这个实例的构造就不需要自己再去写矩阵相乘，也不需要写参数定义这些代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前一样定义了损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前一样我们用一个循环来进行计算训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.1567\n",
      "Epoch [100/300], Loss: 0.0382\n",
      "Epoch [150/300], Loss: 0.0186\n",
      "Epoch [200/300], Loss: 0.0116\n",
      "Epoch [250/300], Loss: 0.0083\n",
      "Epoch [300/300], Loss: 0.0063\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.tensor(X_std,dtype=torch.float)\n",
    "    targets = torch.tensor(y.reshape(-1,1),dtype=torch.float)\n",
    "    outputs = model(inputs)\n",
    "    # Forward pass\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习\n",
    "如何处理多分类的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前我们为了简化问题，我们只用了iris数据集中的两种花，这样训练出来的模型只能预测两种花，如果是要训练真正适合的三分类模型，需要怎么做呢？我们来看一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是先读入数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据分拆开，特征定义为X，标签定义为y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:4].values\n",
    "y = df.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将X进行了标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = np.copy(X)\n",
    "X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()\n",
    "X_std[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()\n",
    "X_std[:,2] = (X[:,2] - X[:,2].mean()) / X[:,2].std()\n",
    "X_std[:,3] = (X[:,3] - X[:,3].mean()) / X[:,3].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个字典，将字符串对应到数字。这时的y不再只有0和1，而是包括了0，1，2三种数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'Setosa':0,'Versicolor':1,'Virginica':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([label_dict[i] for i in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新定义超参数，这里不一样的是我们的ouput_size设置为3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 4\n",
    "hidden_size = 5\n",
    "output_size = 3\n",
    "num_epochs = 300\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型定义是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数定义不一样了，这里的损失函数是定义为CrossEntropyLoss，它是针对多分类问题所需要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.5767\n",
      "Epoch [100/300], Loss: 0.3776\n",
      "Epoch [150/300], Loss: 0.2908\n",
      "Epoch [200/300], Loss: 0.2350\n",
      "Epoch [250/300], Loss: 0.1929\n",
      "Epoch [300/300], Loss: 0.1601\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.tensor(X_std,dtype=torch.float)\n",
    "    targets = torch.tensor(y,dtype=torch.long)\n",
    "    outputs = model(inputs)\n",
    "    # Forward pass\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本课小结：\n",
    "- 本课学习了神经网络的建模，它相比于逻辑回归等方法，仅仅是增加了中间的隐层\n",
    "- pytorch来训练神经网络仍然是四个步骤：定义参数、定义模型、定义损失函数、训练模型。\n",
    "- 二分类和多分类的输出目标不一样，损失函数也不一样。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
